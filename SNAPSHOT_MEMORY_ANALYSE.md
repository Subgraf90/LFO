# Snapshot Memory-Analyse

## √úbersicht

**Ja, Snapshot-Daten werden vollst√§ndig im RAM gespeichert!**

Snapshots werden in `container.calculation_axes` gespeichert und enthalten gro√üe Datenmengen, die komplett im RAM gehalten werden.

---

## 1. Wo werden Snapshots gespeichert?

### Hauptspeicherort

```python
# In DataContainer
self.calculation_axes = {}  # Dictionary mit allen Snapshots

# Struktur:
calculation_axes = {
    "aktuelle_simulation": {...},  # Aktuelle Berechnung
    "Snapshot 1": {...},           # Snapshot 1
    "Snapshot 2": {...},           # Snapshot 2
    ...
}
```

### Speicherung beim Erstellen

```python
# In WindowSnapshotWidget.on_capture_button_clicked()
capture_data = copy.deepcopy(self.container.calculation_axes["aktuelle_simulation"])
# ... f√ºge weitere Daten hinzu ...
self.container.calculation_axes[new_key] = capture_data
```

**Wichtig:** `copy.deepcopy()` erstellt eine vollst√§ndige Kopie aller Daten im RAM!

---

## 2. Was wird in Snapshots gespeichert?

### Gespeicherte Daten

1. **Axis-Plot-Daten** (`calculation_axes["aktuelle_simulation"]`)
   - `x_data_xaxis`, `y_data_xaxis` (NumPy Arrays)
   - `x_data_yaxis`, `y_data_yaxis` (NumPy Arrays)
   - `segment_boundaries_xaxis`, `segment_boundaries_yaxis`

2. **SPL-Feld-Daten** (`calculation_spl`)
   - `sound_field_p` (gro√üe NumPy Arrays)
   - `sound_field_x`, `sound_field_y` (gro√üe NumPy Arrays)
   - `surface_grids` (f√ºr alle Surfaces)
   - `surface_results` (f√ºr alle Surfaces)

3. **FDTD-Simulationsdaten** (`fdtd_simulation`)
   - `pressure_frames` (sehr gro√üe Arrays - 16 Frames pro Periode)
   - `sound_field_x`, `sound_field_y`

4. **Polar-Plot-Daten** (`calculation_polar`)
   - `sound_field_p`
   - `angles`, `frequencies`

5. **Impulse-Daten** (`calculation_impulse`)
   - `magnitude_data`, `phase_response`, `impulse_response`
   - `arrival_times`

### Memory-Verbrauch pro Snapshot

**Gesch√§tzte Gr√∂√üe:**
- **Kleine Projekte**: ~50-200 MB pro Snapshot
- **Mittlere Projekte**: ~200-500 MB pro Snapshot
- **Gro√üe Projekte**: ~500 MB - 2 GB pro Snapshot

**Faktoren:**
- Anzahl Surfaces
- Grid-Resolution
- Anzahl Frequenzen
- FDTD-Frames (16 Frames pro Periode)

---

## 3. Memory-Verbrauch bei mehreren Snapshots

### Beispiel

```python
# 5 Snapshots mit je 200 MB
calculation_axes = {
    "aktuelle_simulation": 200 MB,
    "Snapshot 1": 200 MB,
    "Snapshot 2": 200 MB,
    "Snapshot 3": 200 MB,
    "Snapshot 4": 200 MB,
}
# Total: ~1 GB RAM nur f√ºr Snapshots!
```

### Problem

- **Jeder Snapshot** ist eine vollst√§ndige Kopie aller Berechnungsdaten
- **Keine Limits** ‚Üí Unbegrenztes Wachstum m√∂glich
- **Keine Bereinigung** ‚Üí Altlasten bleiben im RAM

---

## 4. L√∂sungsvorschl√§ge

### Option 1: Memory-Limit f√ºr Snapshots

```python
# In DataContainer
MAX_SNAPSHOT_MEMORY_MB = 2000.0  # 2 GB Limit

def add_snapshot(self, key, data):
    # Sch√§tze Memory-Gr√∂√üe
    memory_mb = estimate_memory_size(data)
    
    # Pr√ºfe Limit
    current_memory = sum(estimate_memory_size(s) for s in self.calculation_axes.values())
    if current_memory + memory_mb > MAX_SNAPSHOT_MEMORY_MB:
        # Entferne √§lteste Snapshots
        # ...
    
    self.calculation_axes[key] = data
```

### Option 2: Snapshot-Count-Limit

```python
MAX_SNAPSHOTS = 10  # Max. 10 Snapshots

def add_snapshot(self, key, data):
    if len(self.calculation_axes) >= MAX_SNAPSHOTS:
        # Entferne √§ltesten Snapshot
        oldest_key = min(self.calculation_axes.keys(), 
                        key=lambda k: self.calculation_axes[k].get('created_at', 0))
        del self.calculation_axes[oldest_key]
    
    self.calculation_axes[key] = data
```

### Option 3: Komprimierung

```python
# Komprimiere gro√üe Arrays beim Speichern
import pickle
import gzip

def compress_snapshot(data):
    pickled = pickle.dumps(data)
    compressed = gzip.compress(pickled)
    return compressed

def decompress_snapshot(compressed):
    pickled = gzip.decompress(compressed)
    return pickle.loads(pickled)
```

### Option 4: File-basierte Snapshots

```python
# Speichere Snapshots auf Disk statt im RAM
SNAPSHOT_DIR = "snapshots/"

def save_snapshot(self, key, data):
    file_path = os.path.join(SNAPSHOT_DIR, f"{key}.pickle")
    with open(file_path, 'wb') as f:
        pickle.dump(data, f)
    # Speichere nur Metadaten im RAM
    self.calculation_axes[key] = {"file_path": file_path, "created_at": time.time()}
```

---

## 5. Empfehlung

### F√ºr Grid-Cache: Memory-basiert

‚úÖ **Cache-Gr√∂√üe speicherbasiert** statt count-basiert:
- Gro√üe Surfaces ‚Üí weniger Eintr√§ge im Cache
- Kleine Surfaces ‚Üí mehr Eintr√§ge im Cache
- Automatische Anpassung an tats√§chlichen Memory-Verbrauch

### F√ºr Snapshots: Count-Limit + Monitoring

‚úÖ **Snapshot-Count-Limit** (z.B. max. 10 Snapshots)
‚úÖ **Memory-Monitoring** f√ºr Snapshots
‚úÖ **Optional: File-basierte Snapshots** f√ºr gro√üe Projekte

---

## 6. Zusammenfassung

### Snapshots im RAM

- ‚úÖ **Ja, vollst√§ndig im RAM** gespeichert
- ‚úÖ **Gro√üe Datenmengen** (~50-500 MB pro Snapshot)
- ‚úÖ **Unbegrenztes Wachstum** m√∂glich
- ‚ö†Ô∏è **Kann RAM sprengen** bei vielen Snapshots

### Cache-Gr√∂√üe

- ‚úÖ **Memory-basiert** statt count-basiert
- ‚úÖ **Automatische Anpassung** an tats√§chlichen Verbrauch
- ‚úÖ **Besser f√ºr gro√üe Surface-Mengen**

Die Snapshot-Speicherung sollte ebenfalls Memory-Management haben! üöÄ

