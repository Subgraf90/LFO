# Cache-Test Anleitung

## √úbersicht

Dieses Dokument beschreibt, wie die Cache-Logik getestet werden kann.

---

## 1. Automatische Tests

### Test-Skript ausf√ºhren

```bash
cd /Users/MGraf/Python/LFO_Umgebung
python test_cache_functionality.py
```

**Oder mit aktivierter Umgebung:**
```bash
/Users/MGraf/Python/LFO_Umgebung/Venv_FEM/bin/python test_cache_functionality.py
```

### Getestete Funktionalit√§ten

1. ‚úÖ **Cache-Manager Grundfunktionalit√§t**
   - Cache registrieren
   - Cache abrufen
   - Cache-Statistiken

2. ‚úÖ **LRU-Cache Verhalten**
   - Cache-F√ºllung
   - LRU-Eviction (√§lteste Eintr√§ge werden entfernt)
   - Cache-Zugriff

3. ‚úÖ **Cache Hit/Miss**
   - Cache Miss bei nicht vorhandenem Key
   - Cache Hit bei vorhandenem Key
   - Hit-Rate Berechnung

4. ‚úÖ **Gezielte Cache-Invalidierung**
   - Invalidierung mit Pr√§dikat-Funktion
   - Nur bestimmte Eintr√§ge werden entfernt
   - Andere Eintr√§ge bleiben erhalten

5. ‚úÖ **Shared Grid-Generator**
   - Grid-Generator mit Shared Cache
   - Cache-Persistenz √ºber mehrere Instanzen

6. ‚úÖ **Surface-Cache Invalidierung**
   - `invalidate_surface_cache()` Funktionalit√§t
   - Nur betroffene Surfaces werden invalidiert

7. ‚úÖ **Cache-Statistiken**
   - Hits, Misses, Size, Hit-Rate
   - Globale Statistiken

8. ‚úÖ **Thread-Safety**
   - Parallele Zugriffe ohne Fehler
   - Lock-Mechanismus funktioniert

9. ‚úÖ **Cache-Konfiguration**
   - Zur Laufzeit konfigurierbar
   - max_size, description

10. ‚úÖ **Mehrere Cache-Typen**
    - Verschiedene Cache-Typen gleichzeitig
    - Globale Statistiken √ºber alle Caches

---

## 2. Manuelle Tests in der Anwendung

### Test 1: Cache-Hit bei wiederholter Berechnung

**Schritte:**
1. √ñffne LFO
2. Erstelle ein Surface
3. F√ºhre SPL-Berechnung aus (erste Berechnung)
4. F√ºhre SPL-Berechnung erneut aus (zweite Berechnung)

**Erwartetes Ergebnis:**
- Erste Berechnung: Cache Miss (Grid wird berechnet)
- Zweite Berechnung: Cache Hit (Grid aus Cache)
- Zweite Berechnung sollte **deutlich schneller** sein

**√úberpr√ºfung:**
```python
# In Python-Konsole oder Debugger
from Module_LFO.Modules_Init.CacheManager import cache_manager, CacheType

stats = cache_manager.get_cache_stats(CacheType.GRID)
print(f"Grid Cache Hit-Rate: {stats['grid']['stats']['hit_rate']:.2f}%")
print(f"Hits: {stats['grid']['stats']['hits']}")
print(f"Misses: {stats['grid']['stats']['misses']}")
```

### Test 2: Gezielte Surface-Cache Invalidierung

**Schritte:**
1. Erstelle zwei Surfaces: "surface_1" und "surface_2"
2. F√ºhre SPL-Berechnung aus (beide Surfaces werden gecacht)
3. √Ñndere nur "surface_1" (z.B. H√∂he √§ndern)
4. F√ºhre SPL-Berechnung erneut aus

**Erwartetes Ergebnis:**
- "surface_1": Cache Miss (wird neu berechnet)
- "surface_2": Cache Hit (aus Cache)
- Nur "surface_1" sollte neu berechnet werden

**√úberpr√ºfung:**
```python
# Cache-Statistiken vor/nach √Ñnderung vergleichen
stats_before = cache_manager.get_cache_stats(CacheType.GRID)
# ... √Ñnderung ...
stats_after = cache_manager.get_cache_stats(CacheType.GRID)
# Pr√ºfe dass nur surface_1 invalidiert wurde
```

### Test 3: Hide/Disable Cache-Invalidierung

**Schritte:**
1. Erstelle ein Surface
2. F√ºhre SPL-Berechnung aus (Surface wird gecacht)
3. Setze Surface auf "hide"
4. F√ºhre SPL-Berechnung erneut aus

**Erwartetes Ergebnis:**
- Cache f√ºr verstecktes Surface wird gel√∂scht
- Verstecktes Surface wird nicht berechnet
- Bei Unhide: Surface wird neu berechnet (Cache wurde gel√∂scht)

**√úberpr√ºfung:**
```python
# Pr√ºfe Cache-Gr√∂√üe vor/nach hide
stats_before = cache_manager.get_cache_stats(CacheType.GRID)
# ... hide ...
stats_after = cache_manager.get_cache_stats(CacheType.GRID)
# Cache-Gr√∂√üe sollte kleiner sein
```

### Test 4: Shared Grid-Generator

**Schritte:**
1. √ñffne LFO
2. F√ºhre erste SPL-Berechnung aus
3. F√ºhre zweite SPL-Berechnung aus (ohne √Ñnderungen)

**Erwartetes Ergebnis:**
- Beide Berechnungen verwenden denselben Grid-Generator
- Cache bleibt zwischen Berechnungen erhalten
- Zweite Berechnung nutzt Cache

**√úberpr√ºfung:**
```python
# Pr√ºfe dass Grid-Generator geteilt wird
main_window = ...  # MainWindow-Instanz
grid_gen_1 = main_window._grid_generator
# ... Berechnung ...
grid_gen_2 = main_window._grid_generator
assert grid_gen_1 is grid_gen_2, "Sollte dieselbe Instanz sein"
```

### Test 5: Gruppen-H√∂hen√§nderung ohne Rand-Surface-√Ñnderung

**Schritte:**
1. Erstelle eine Surface-Gruppe mit einem Surface
2. Erstelle ein Rand-Surface (nicht in Gruppe, teilt Punkte)
3. √Ñndere H√∂he der Gruppe
4. Pr√ºfe Rand-Surface

**Erwartetes Ergebnis:**
- Gruppe wird verschoben ‚úÖ
- Rand-Surface bleibt unver√§ndert ‚úÖ
- Geteilte Punkte werden kopiert, nicht verschoben

**√úberpr√ºfung:**
```python
# Pr√ºfe Punkt-Koordinaten vor/nach √Ñnderung
rand_surface_points_before = [...]
# ... Gruppen-√Ñnderung ...
rand_surface_points_after = [...]
assert rand_surface_points_before == rand_surface_points_after, "Rand-Surface sollte unver√§ndert sein"
```

---

## 3. Performance-Tests

### Test: Cache-Performance messen

**Skript:**
```python
import time
from Module_LFO.Modules_Init.CacheManager import cache_manager, CacheType

# Cache leeren
cache_manager.clear_cache(CacheType.GRID)
cache = cache_manager.get_cache(CacheType.GRID)

# Test 1: Cache Miss (erste Berechnung)
start = time.perf_counter()
# ... Berechnung ...
duration_miss = time.perf_counter() - start
print(f"Cache Miss: {duration_miss:.3f}s")

# Test 2: Cache Hit (zweite Berechnung)
start = time.perf_counter()
# ... Berechnung ...
duration_hit = time.perf_counter() - start
print(f"Cache Hit: {duration_hit:.3f}s")

# Verbesserung berechnen
improvement = ((duration_miss - duration_hit) / duration_miss) * 100
print(f"Verbesserung: {improvement:.1f}%")
```

**Erwartete Ergebnisse:**
- Cache Hit sollte **50-90% schneller** sein als Cache Miss
- Hit-Rate sollte nach mehreren Berechnungen **>70%** sein

---

## 4. Debugging und Monitoring

### Cache-Statistiken anzeigen

**In Python-Konsole:**
```python
from Module_LFO.Modules_Init.CacheManager import cache_manager, CacheType

# Einzelner Cache
stats = cache_manager.get_cache_stats(CacheType.GRID)
print(f"Grid Cache:")
print(f"  Hits: {stats['grid']['stats']['hits']}")
print(f"  Misses: {stats['grid']['stats']['misses']}")
print(f"  Hit-Rate: {stats['grid']['stats']['hit_rate']:.2f}%")
print(f"  Size: {stats['grid']['stats']['size']}/{stats['grid']['config']['max_size']}")

# Alle Caches
global_stats = cache_manager.get_global_stats()
print(f"\nGlobal:")
print(f"  Total Caches: {global_stats['total_caches']}")
print(f"  Global Hit-Rate: {global_stats['global_hit_rate']:.2f}%")
print(f"  Total Size: {global_stats['total_size']}")
```

### Cache-Inhalt anzeigen

**F√ºr Debugging:**
```python
cache = cache_manager.get_cache(CacheType.GRID)
with cache._lock:
    print(f"Cache-Keys: {list(cache._cache.keys())[:10]}")  # Erste 10 Keys
    print(f"Cache-Gr√∂√üe: {len(cache._cache)}")
```

### Cache zur√ºcksetzen

**F√ºr saubere Tests:**
```python
# Einzelner Cache
cache_manager.clear_cache(CacheType.GRID)

# Alle Caches
cache_manager.clear_all_caches()

# Statistiken zur√ºcksetzen (beh√§lt Cache-Inhalt)
cache_manager.reset_stats(CacheType.GRID)
```

---

## 5. Integrationstests

### Test: Vollst√§ndiger Workflow

**Szenario:**
1. LFO starten
2. Surface erstellen
3. SPL berechnen (Cache Miss)
4. SPL erneut berechnen (Cache Hit)
5. Surface √§ndern (Cache Invalidierung)
6. SPL berechnen (Cache Miss f√ºr ge√§ndertes Surface)
7. Hide Surface (Cache Invalidierung)
8. Unhide Surface (Cache wird neu erstellt)

**Erwartetes Ergebnis:**
- Alle Schritte funktionieren ohne Fehler
- Cache-Verhalten ist korrekt
- Performance-Verbesserung bei Cache Hits

---

## 6. Fehlerbehandlung

### H√§ufige Probleme

**Problem 1: Cache wird nicht geteilt**
```python
# Pr√ºfe ob Grid-Generator geteilt wird
assert main_window._grid_generator is not None, "Grid-Generator sollte existieren"
assert calculator._grid_generator is main_window._grid_generator, "Sollte geteilt werden"
```

**Problem 2: Cache wird nicht invalidiert**
```python
# Pr√ºfe Cache-Gr√∂√üe vor/nach Invalidierung
stats_before = cache.get_stats()
grid_generator.invalidate_surface_cache("surface_1")
stats_after = cache.get_stats()
assert stats_after.size < stats_before.size, "Cache sollte kleiner sein"
```

**Problem 3: Thread-Safety Probleme**
```python
# Pr√ºfe auf Race Conditions
# F√ºhre parallele Zugriffe aus und pr√ºfe auf Fehler
```

---

## 7. Best Practices

### Testen in der Entwicklung

1. **Vor jeder √Ñnderung:** Tests ausf√ºhren
2. **Nach jeder √Ñnderung:** Tests erneut ausf√ºhren
3. **Bei Problemen:** Debugging mit Statistiken

### Monitoring in Produktion

1. **Cache-Statistiken regelm√§√üig pr√ºfen**
2. **Hit-Rate √ºberwachen** (sollte >70% sein)
3. **Cache-Gr√∂√üe √ºberwachen** (sollte nicht unbegrenzt wachsen)

### Performance-Optimierung

1. **Cache-Gr√∂√üe anpassen** wenn n√∂tig
2. **File-Cache aktivieren** f√ºr gro√üe Projekte
3. **Cache-Invalidierung optimieren** wenn zu langsam

---

## 8. Zusammenfassung

### Test-Methoden

1. ‚úÖ **Automatische Tests:** `test_cache_functionality.py`
2. ‚úÖ **Manuelle Tests:** In der Anwendung
3. ‚úÖ **Performance-Tests:** Messung der Verbesserung
4. ‚úÖ **Integrationstests:** Vollst√§ndiger Workflow

### Wichtige Metriken

- **Hit-Rate:** Sollte >70% sein
- **Performance-Verbesserung:** 50-90% bei Cache Hits
- **Cache-Gr√∂√üe:** Sollte begrenzt bleiben (LRU-Eviction)

Die Tests sollten regelm√§√üig ausgef√ºhrt werden, um sicherzustellen, dass die Cache-Logik korrekt funktioniert! üöÄ

