# Cache Memory-Management

## Ãœbersicht

Das Cache-System verwendet **mehrschichtige Memory-Limits**, um sicherzustellen, dass der RAM nicht Ã¼berlastet wird:

1. **Count-basierte Limits** (`max_size`) - Begrenzt Anzahl EintrÃ¤ge
2. **Memory-basierte Limits** (`max_memory_mb`) - Begrenzt Memory-Verbrauch
3. **LRU-Eviction** - Entfernt Ã¤lteste EintrÃ¤ge automatisch
4. **Memory-Monitoring** - Ãœberwacht Memory-Verbrauch und warnt bei hoher Auslastung

---

## 1. Memory-basierte Limits

### Konfiguration

```python
from Module_LFO.Modules_Init.CacheManager import cache_manager, CacheType

# Cache mit Memory-Limit registrieren
cache_manager.register_cache(
    CacheType.GRID,
    max_size=1000,           # Max. 1000 EintrÃ¤ge
    max_memory_mb=500.0,    # Max. 500 MB Memory
    description="Grid Cache mit Memory-Limit"
)
```

### Verhalten

- **Beide Limits werden geprÃ¼ft**: Sowohl `max_size` als auch `max_memory_mb`
- **Memory-Limit hat PrioritÃ¤t**: Wenn Memory-Limit erreicht wird, werden Ã¤lteste EintrÃ¤ge entfernt
- **Count-Limit als Fallback**: Wenn Memory-Limit nicht gesetzt ist, wird nur Count-Limit verwendet

### Beispiel

```python
# Cache mit 500 MB Limit
cache = cache_manager.register_cache(
    CacheType.GRID,
    max_size=1000,
    max_memory_mb=500.0
)

# Wenn ein neuer Eintrag hinzugefÃ¼gt wird:
# 1. PrÃ¼fe Memory-Limit: Aktueller Verbrauch + neuer Eintrag > 500 MB?
#    â†’ Ja: Entferne Ã¤lteste EintrÃ¤ge bis genug Platz
# 2. PrÃ¼fe Count-Limit: Anzahl EintrÃ¤ge >= 1000?
#    â†’ Ja: Entferne Ã¤ltesten Eintrag
# 3. FÃ¼ge neuen Eintrag hinzu
```

---

## 2. Memory-SchÃ¤tzung

### Automatische SchÃ¤tzung

Das System schÃ¤tzt automatisch die Memory-GrÃ¶ÃŸe jedes Cache-Eintrags:

```python
def estimate_memory_size(obj: Any) -> float:
    """
    SchÃ¤tzt Memory-GrÃ¶ÃŸe in MB.
    
    UnterstÃ¼tzt:
    - NumPy Arrays (genaue GrÃ¶ÃŸe via .nbytes)
    - Dataclasses (summiert alle Attribute)
    - Standard Python-Objekte (sys.getsizeof)
    """
```

### UnterstÃ¼tzte Objekte

- âœ… **NumPy Arrays**: Genaue GrÃ¶ÃŸe via `array.nbytes`
- âœ… **CachedSurfaceGrid**: Summiert alle NumPy-Arrays
- âœ… **Standard Python-Objekte**: `sys.getsizeof()`

### Beispiel

```python
import numpy as np
from Module_LFO.Modules_Calculate.FlexibleGridGenerator import CachedSurfaceGrid

# NumPy Array
arr = np.zeros((1000, 1000), dtype=np.float64)
memory_mb = estimate_memory_size(arr)  # ~7.6 MB

# CachedSurfaceGrid
cached_grid = CachedSurfaceGrid(
    surface_id="surface_1",
    X_grid=np.zeros((100, 100)),
    Y_grid=np.zeros((100, 100)),
    Z_grid=np.zeros((100, 100)),
    # ...
)
memory_mb = estimate_memory_size(cached_grid)  # Summiert alle Arrays
```

---

## 3. Memory-Monitoring

### Statistiken

```python
from Module_LFO.Modules_Init.CacheManager import cache_manager, CacheType

# Cache-Statistiken abrufen
stats = cache_manager.get_cache_stats(CacheType.GRID)
print(f"Memory-Verbrauch: {stats['grid']['stats']['memory_usage_mb']:.1f} MB")
print(f"Memory-Evictions: {stats['grid']['stats']['memory_evictions']}")
```

### Warnungen

Das System warnt automatisch bei hoher Memory-Auslastung:

```
âš ï¸  WARNUNG: Cache 'grid' nutzt 92.3% des Memory-Limits (461.5MB / 500.0MB)
```

**Threshold:** 90% des Memory-Limits

### Globale Statistiken

```python
global_stats = cache_manager.get_global_stats()
print(f"Total Memory: {sum(s['stats']['memory_usage_mb'] for s in global_stats['caches'].values()):.1f} MB")
```

---

## 4. Adaptive Cache-GrÃ¶ÃŸen

### Automatische Anpassung basierend auf verfÃ¼gbarem RAM

```python
def get_adaptive_cache_size(cache_type: CacheType, default_mb: float = 500.0) -> float:
    """
    Berechnet adaptive Cache-GrÃ¶ÃŸe basierend auf verfÃ¼gbarem RAM.
    
    Strategie:
    - Nutze 10% des verfÃ¼gbaren RAMs fÃ¼r Cache
    - Minimum: 100 MB
    - Maximum: default_mb
    """
    if not PSUTIL_AVAILABLE:
        return default_mb
    
    try:
        available_memory_gb = psutil.virtual_memory().available / (1024**3)
        adaptive_mb = (available_memory_gb * 1024) * 0.1  # 10% des verfÃ¼gbaren RAMs
        return max(100.0, min(adaptive_mb, default_mb))
    except Exception:
        return default_mb
```

### Verwendung

```python
# In Main.py
adaptive_memory_mb = get_adaptive_cache_size(CacheType.GRID, default_mb=500.0)
cache_manager.register_cache(
    CacheType.GRID,
    max_size=1000,
    max_memory_mb=adaptive_memory_mb
)
```

---

## 5. Best Practices

### FÃ¼r groÃŸe Surface-Mengen

**Problem:** Viele Surfaces â†’ Hoher Memory-Verbrauch

**LÃ¶sung:**

1. **Memory-Limit setzen:**
```python
cache_manager.register_cache(
    CacheType.GRID,
    max_size=1000,
    max_memory_mb=1000.0  # 1 GB Limit
)
```

2. **File-Cache aktivieren** (fÃ¼r persistente Speicherung):
```python
cache_manager.register_cache(
    CacheType.GRID,
    max_size=1000,
    max_memory_mb=500.0,
    enable_file_cache=True
)
```

3. **Adaptive GrÃ¶ÃŸen verwenden:**
```python
adaptive_mb = get_adaptive_cache_size(CacheType.GRID, default_mb=500.0)
cache_manager.register_cache(
    CacheType.GRID,
    max_size=1000,
    max_memory_mb=adaptive_mb
)
```

### Monitoring

```python
# RegelmÃ¤ÃŸig Memory-Verbrauch prÃ¼fen
from Module_LFO.Modules_Init.CacheMonitor import CacheMonitor

monitor = CacheMonitor()
monitor.print_stats()  # Zeigt Memory-Verbrauch

# Bei hoher Auslastung: Cache leeren oder Limit erhÃ¶hen
if stats['grid']['stats']['memory_usage_mb'] > 450:
    cache_manager.clear_cache(CacheType.GRID)
    # Oder Limit erhÃ¶hen
    cache_manager.configure_cache(CacheType.GRID, max_memory_mb=1000.0)
```

---

## 6. Konfiguration in Main.py

### Aktuelle Konfiguration

```python
def _initialize_caches(self):
    # Grid Cache: GroÃŸer Cache fÃ¼r viele Surfaces
    cache_manager.register_cache(
        CacheType.GRID,
        max_size=int(getattr(self.settings, "surface_grid_cache_size", 1000)),
        max_memory_mb=float(getattr(self.settings, "surface_grid_cache_memory_mb", 500.0)),
        description="Surface Grid Cache"
    )
```

### Settings-Integration

```python
# In settings_state.py oder UI
settings.surface_grid_cache_size = 1000
settings.surface_grid_cache_memory_mb = 500.0  # 500 MB Limit
```

---

## 7. Memory-Eviction Strategie

### LRU-Eviction

**PrioritÃ¤t:**
1. **Memory-Limit** (wenn gesetzt): Entfernt Ã¤lteste EintrÃ¤ge bis Memory-Limit eingehalten wird
2. **Count-Limit**: Entfernt Ã¤ltesten Eintrag wenn Count-Limit erreicht

### Beispiel

```python
# Cache mit 500 MB Limit, aktuell 480 MB belegt
cache.set("new_large_entry", large_object)  # 50 MB

# Was passiert:
# 1. PrÃ¼fe Memory: 480 + 50 = 530 MB > 500 MB Limit
# 2. Entferne Ã¤lteste EintrÃ¤ge bis < 450 MB (Platz fÃ¼r 50 MB)
# 3. FÃ¼ge neuen Eintrag hinzu
# 4. Aktueller Verbrauch: ~500 MB
```

---

## 8. Zusammenfassung

### Features

- âœ… **Memory-basierte Limits**: Verhindert RAM-Ãœberlastung
- âœ… **Automatische Memory-SchÃ¤tzung**: FÃ¼r NumPy Arrays und Dataclasses
- âœ… **LRU-Eviction**: Entfernt Ã¤lteste EintrÃ¤ge automatisch
- âœ… **Memory-Monitoring**: Ãœberwacht Verbrauch und warnt bei hoher Auslastung
- âœ… **Adaptive GrÃ¶ÃŸen**: Passt sich an verfÃ¼gbaren RAM an

### Wichtige Einstellungen

```python
# FÃ¼r groÃŸe Surface-Mengen:
max_memory_mb = 1000.0  # 1 GB Limit

# FÃ¼r normale Nutzung:
max_memory_mb = 500.0   # 500 MB Limit

# FÃ¼r kleine Projekte:
max_memory_mb = 100.0   # 100 MB Limit
```

### Monitoring

```python
# Memory-Verbrauch prÃ¼fen
stats = cache_manager.get_cache_stats(CacheType.GRID)
print(f"Memory: {stats['grid']['stats']['memory_usage_mb']:.1f} MB")
print(f"Limit: {stats['grid']['config']['max_memory_mb']:.1f} MB")
```

Das Memory-Management verhindert, dass der Cache den RAM sprengt! ğŸš€

